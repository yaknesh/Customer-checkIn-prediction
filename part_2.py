# -*- coding: utf-8 -*-
"""Part-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V1yODg1aNt3GLpEsFb5F9YOayi5FcjoE

#Part-2
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

from google.colab import files
files.upload()

df=pd.read_csv('/content/train_data_evaluation_part_2.csv')
df.head()

df.info()

df.drop('ID',axis='columns',inplace=True)

df.drop('Unnamed: 0',axis='columns',inplace=True)

corrmat=df.corr()
top_corr_features=corrmat.index
plt.figure(figsize=(20,20))
g=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap="RdYlGn")

df['Age']=df['Age'].fillna(df['Age'].mean())

df['Total_revenue']=df['LodgingRevenue']+df['OtherRevenue']

df.drop(['LodgingRevenue','OtherRevenue'],axis='columns',inplace=True)

df['Churn']=0

df.head()

df['Churn']=np.where(df['BookingsCheckedIn']==0,0,1)

df.drop('BookingsCheckedIn',axis='columns',inplace=True)

def unique_col_value(df):
  for i in df:
    if df[i].dtype=='object':
      print(f'{i} : {df[i].unique()}')

unique_col_value(df)

from sklearn import preprocessing
label_encoder = preprocessing.LabelEncoder()
df['country']= label_encoder.fit_transform(df['Nationality'])

var=['DistributionChannel','MarketSegment']
for item in var:
  df[item]=label_encoder.fit_transform(df[item])
df2=pd.get_dummies(df,columns=['DistributionChannel','MarketSegment'])

df2.head()

corr=df2.corr(method='pearson')['Churn'][:]
corr

train=df2.drop(['Nationality', 'Age', 'BookingsCanceled', 'BookingsNoShowed','SRHighFloor', 'SRLowFloor',
       'SRAccessibleRoom', 'SRMediumFloor', 'SRBathtub', 'SRShower', 'SRCrib',
       'SRKingSizeBed', 'SRTwinBed', 'SRNearElevator', 'SRAwayFromElevator',
       'SRNoAlcoholInMiniBar', 'SRQuietRoom', 'Churn',
       'country','DistributionChannel_0',
       'DistributionChannel_1', 'DistributionChannel_2',
       'DistributionChannel_3', 'MarketSegment_0', 'MarketSegment_1',
       'MarketSegment_2', 'MarketSegment_3', 'MarketSegment_4',
       'MarketSegment_5', 'MarketSegment_6'], axis=1)

train.columns

col=['DaysSinceCreation', 'AverageLeadTime', 'PersonsNights', 'RoomNights', 'DaysSinceLastStay', 'DaysSinceFirstStay', 'Total_revenue']
from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
train[col]=scaler.fit_transform(train[col])

train.sample(5)

X=train.copy()
y=df2['Churn']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)

import tensorflow as tf
from tensorflow import keras


model = keras.Sequential([
    keras.layers.Dense(7, input_shape=(7,), activation='relu'),
    keras.layers.Dense(5, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid')
])

# opt = keras.optimizers.Adam(learning_rate=0.01)

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.fit(X_train, y_train, epochs=5)

test_dataset=pd.read_csv('/content/test_data_evaluation_part2.csv')

test_dataset.drop('ID',axis='columns',inplace=True)

test_dataset.drop('Unnamed: 0',axis='columns',inplace=True)

test_dataset['Age']=test_dataset['Age'].fillna(test_dataset['Age'].mean())

test_dataset['Total_revenue']=test_dataset['LodgingRevenue']+test_dataset['OtherRevenue']

test_dataset.drop(['LodgingRevenue','OtherRevenue'],axis='columns',inplace=True)

test_dataset.drop('BookingsCheckedIn',axis='columns',inplace=True)

from sklearn import preprocessing
label_encoder = preprocessing.LabelEncoder()
test_dataset['country']= label_encoder.fit_transform(test_dataset['Nationality'])

var=['DistributionChannel','MarketSegment']
for item in var:
  test_dataset[item]=label_encoder.fit_transform(test_dataset[item])
test_df=pd.get_dummies(test_dataset,columns=['DistributionChannel','MarketSegment'])

test=test_df.drop(['Nationality', 'Age', 'BookingsCanceled', 'BookingsNoShowed','SRHighFloor', 'SRLowFloor',
       'SRAccessibleRoom', 'SRMediumFloor', 'SRBathtub', 'SRShower', 'SRCrib',
       'SRKingSizeBed', 'SRTwinBed', 'SRNearElevator', 'SRAwayFromElevator',
       'SRNoAlcoholInMiniBar', 'SRQuietRoom',
       'country','DistributionChannel_0',
       'DistributionChannel_1', 'DistributionChannel_2',
       'DistributionChannel_3', 'MarketSegment_0', 'MarketSegment_1',
       'MarketSegment_2', 'MarketSegment_3', 'MarketSegment_4',
       'MarketSegment_5'], axis=1)

col=['DaysSinceCreation', 'AverageLeadTime', 'PersonsNights', 'RoomNights', 'DaysSinceLastStay', 'DaysSinceFirstStay', 'Total_revenue']
scaler=MinMaxScaler()
test[col]=scaler.fit_transform(test[col])

result_predict=model.predict(test)

result_predict[:20]


import streamlit as st

def predict_note_authentication(DaysSinceCreation, AverageLeadTime, PersonsNights, RoomNights, DaysSinceLastStay, DaysSinceFirstStay, Total_revenue):
  prediction=model.predict([[DaysSinceCreation, AverageLeadTime, PersonsNights, RoomNights, DaysSinceLastStay, DaysSinceFirstStay, Total_revenue]])
  print(prediction)
  return prediction

header=st.beta_container()
model=st.beta_container()

def main():
    st.title("Bank Authenticator")
    DaysSinceCreation = st.text_input("DaysSinceCreation","Type Here")
    AverageLeadTime = st.text_input("AverageLeadTime","Type Here")
    PersonsNights = st.text_input("PersonsNights","Type Here")
    RoomNights = st.text_input("RoomNights","Type Here")
    DaysSinceLastStay = st.text_input("DaysSinceLastStay","Type Here")
    DaysSinceFirstStay = st.text_input("DaysSinceFirstStay","Type Here")
    Total_revenue = st.text_input("Total_revenue","Type Here")
    result=""
    if st.button("Predict"):
      result=predict_note_authentication(variance,skewness,curtosis,entropy)
    st.success('The output is {}'.format(result))

if __name__=='__main__':
    main()

